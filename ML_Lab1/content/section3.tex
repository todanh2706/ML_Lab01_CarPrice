\pagebreak
\section{Lý thuyết về các mô hình và lựa chọn}
% \subsection{Mô hình Linear Regression ~\cite{MachineLarning}}
% Linear regression là một mô hình học có giám sát với khả năng tìm mối liên hệ tuyến tính giữa input và output.\\
% \textbf{Vấn đề:} Model này nhận vào một vector $x \in \mathbb{R}^{D+1}$ gồm các đặt trưng của một mẫu và trả về giá trị dự đoán $y \in \mathbb{R}$. Ví dụ: Nhận vào các giá trị thuộc tính của một ngôi nhà như Diện tích sàn ($m^2$), số lượng phòng ngủ, khoảng cách tới trung tâm thành phố (m), tuổi nhà (năm) và trả về dự đoán giá của căn nhà đó.\\
% \textbf{Đánh giá hiệu năng: }Mô hình Linear Regression thường được đánh giá bằng Mean Square Error (MSE) trên tập train:\\
% \[
% MSE_{\text{train}} = \frac{1}{N} \| \hat{\mathbf{y}} - \mathbf{y} \|^2 = \frac{1}{N} \sum_{n=1}^{N} (\hat{y}_n - y_n)^2
% \]
% với $\hat{\mathbf{y}}$ là tập giá trị dự đoán, $\mathbf{y}$ là tập giá trị thực tế của tập train.\\
% \textbf{Huấn luyện mô hình}: Các phương pháp huấn luyện mô hình Linear Regression được dựa trên cách tính toán vector trọng số $\omega$ để giảm MSE xuống thấp nhất. Một cách làm phổ biến là tính toán đạo hàm của hàm MSE theo $\omega$ và cho nó bằng 0 để tìm cực tiểu.
% \[
% \nabla_{\mathbf{w}} (MSE_{\text{train}}) = \nabla_{\mathbf{w}} (\mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{w}^T \mathbf{X}^T \mathbf{y} - \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{y}^T \mathbf{y}) = 2\mathbf{X}^T \mathbf{X} \mathbf{w} - 2\mathbf{X}^T \mathbf{y}
% \]

% \begin{align*}
% \nabla_{\mathbf{w}} (MSE_{\text{train}}) &= 0 \\
% \mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{X}^T \mathbf{y} &= 0 \\
% \mathbf{X}^T \mathbf{X} \mathbf{w} &= \mathbf{X}^T \mathbf{y} \\
% \mathbf{w} &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
% \end{align*}
\subsection{Mô hình Linear Regression}
\subsection{Cơ sở lý thuyết}
Hồi quy tuyến tính (\textbf{\textit{Linear Regression}}) là một trong những mô hình học có giám sát nền tảng, được sử dụng để mô hình hoá mối quan hệ tuyến tính giữa một biến phụ (hay biến đầu) ra thuộc và một hoặc nhiều biến độc lập (hay biến thuộc tính đầu vào). Mô hình giả định rằng giá trị mục tiêu $y$ có thể được biểu diễn dưới dạng một tổ hợp tuyến tính các đặc trưng $X$.\\
Mục tiêu của mô hình là tìm ra vector trọng số $w$ để tối thiểu hoá hàm mất mát. Đối với hồi quy tuyến tính cơ bản, hàm mất mát thường là \textit{Mean Square Error} (MSE). Hàm mục tiêu này có dạng
\begin{center}
    $\displaystyle J(w) = \frac{1}{N}.\|y-Xw\|^2_2$. \cite{MSE}
\end{center}
Trong đó, $X$ là ma trận thuộc tính, $y$ là vector giá trị thực tế, $w$ là vector trọng số cần tìm và $N$ là số lượng mẫu.\\
Khác với các phương pháp tối ưu dựa trên Gradient Descent, hồi quy tuyến tính cơ bản có một nghiệm dạng đóng (\textit{closed-form solution}) là $\displaystyle w=\left(X^TX\right)^{-1}X^Ty$. \cite{ClosedFormSolution}\\
Mô hình hồi quy tuyến tính cơ bản không chứa các siêu tham số điều chuẩn (\textit{regularization hyperparameter}) như Ridge hay Lasso. Do đó, độ phức tạp của mô hình và nguy cơ quá khớp (\textit{overfitting}) phụ thuộc trực tiếp vào số lượng và chất lượng của bộ thuộc tính đầu vào, bộ thuộc tính đã qua một bước chọn lọc bằng Forward Selection sử dụng chỉ số BIC.
\subsubsection{Triển khai thực nghiệm}
Trong đồ án này, mô hình hồi quy tuyến tính không được huấn luyện trên toàn bộ thuộc tính. Thay vào đó, nó được kết hợp với một kỹ thuật lựa chọn thuộc tính tự động, như đã nói đó là Forward Selection kết hợp với BIC. Toàn bộ quá trình diễn ra như sau:
\begin{itemize}
    \item \textbf{Pipeline:} Mô hình được đóng gói trong một \texttt{sklearn.pipeline.Pipeline} để chuẩn hoá quy trình xử lý.
    \item \textbf{Tiền xử lý (Preprocessing):} Bước đầu tiên trong pipeline là mã hoá one-hot cho các biến phân loại và áp dụng \texttt{StandardScaler} cho các biến số.
    \item \textbf{Lựa chọn thuộc tính (Feature Selection):} Điểm khác biệt mấu chốt của pipeline này là bước \texttt{bic\_selector}. Thay vì dùng tất cả thuộc tính, mô hình sẽ sử dụng kỹ thuật lựa chọn đặc trưng để lọc ra một bộ thuộc tính phù hợp nhằm gia tăng hiệu suất.
    \item \textbf{Cấu hình:} Mô hình hồi quy tuyến tính \texttt{sklearn.linear\_model.LinearRegression} được khởi tạo với các tham số mặc định, huấn luyện trên bộ thuộc tính đã được chọn.
\end{itemize}

\subsection{Mô hình Ridge}
\subsubsection{Cơ sở lý thuyết}
Hồi quy Ridge (\textbf{\textit{Ridge Regression}}) là một kỹ thuật hồi quy tuyến tính đuọc điều chỉnh (\textit{regularized}) nhằm giải quyết hiện tượng quá khớp (\textit{overfitting}) bằng cách dùng các kỹ thuật Chính quy hoá (\textit{Regularization}). Phương pháp này thêm một số hạng (thường là \textit{penalty}) vào hàm mất mát (\textit{loss function}) của mô hình. Thành phần phạt này dùng để đánh giá và kiểm soát độ phức tạp của mô hình\\
Cụ thể, mô hình Ridge sử dụng kỹ thuật \textit{L2 Regularization}, thay vì chỉ tối thiểu hoá tổng bình phương sai số (\textit{Mean Square Error - MSE}) như mô hình hồi quy tuyến tính cơ bản thì Ridge sẽ tối thiểu hoá một hàm mục tiêu mới:
\begin{center}
    $\displaystyle J(w)=\frac{1}{2}\|\mathbf{y}-\mathbf{X}\mathbf{w}\|_2^2+\lambda.\|\mathbf{w}\|_2^2$ \cite{Vu_2017}
\end{center}
Trong đó, $\mathbf{w}$ là vector trọng số của mô hình và $\lambda$ là siêu tham số (\textit{hyperparameter}) điều chỉnh độ mạnh của thành phần phạt $\|\mathbf{w}\|_2^2$.\\
\cite{Ridge} Việc thêm thành phần phạt sẽ ép các trọng số của mô hình phải giữ ở mức nhỏ, co về gần 0. Điều này làm giảm sự phụ thuộc của mô hình vào bất kỳ một biến đầu vào cụ thể nào, khiến mô hình đơn giản hơn, ít nhạy cảm với nhiễu dữ liệu và tăng khả năng tổng quát hoá. Vì thế, bài toán tối ưu hàm mất mát của hồi quy Ridge thực chất là tối ưu song song hai thành phần bao gồm tổng bình phương sai số và thành phần phạt hay thành phần điều chuẩn (\textit{regularization term}).
\begin{itemize}
    \item Trường hợp $\lambda=0$, thành phần điều chuẩn bị tiêu giảm và chúng ta quay về hồi quy tuyến tính.
    \item Trường hợp $\lambda \approx 0$, thành phần điều chuẩn trở nên ít quan trọng, mức độ kiểm soát quá khớp trở nên kém.
    \item Trường hợp $\lambda$ lớn, mức độ kiểm soát lên độ lớn của các hệ số ước lượng tăng lên qua đó giảm bớt quá khớp.
\end{itemize}
Khi $\lambda$ tăng dần, hồi quy Ridge có xu hướng thu hẹp hệ số ước lượng $\mathbf{w}$ từ mô hình.
\subsubsection{Triển khai thực nghiệm}
Mô hình Ridge được triển khai và cấu hình như sau:
\begin{itemize}
    \item Pipeline: Mô hình được gói trong một \texttt{sklearn.pipeline.Pipeline} để chuẩn hoá quy trình xử lý.
    \item Chuẩn hoá (Scaling): Bước đầu tiên trong pipeline là chuẩn hoá dữ liệu, rất quan trọng đối với các mô hình được chính quy hoá như Ridge, vì thành phần phạt nhạy cảm với sự chênh lệch về thang đo (\textit{scale}) của các biến đầu vào.
    \item Cấu hình: Mô hình Ridge được khởi tạo với siêu tham số \texttt{alpha=33.6} và \texttt{random\_state=42} (được dùng để đảm bảo kết quả có thể được tái lập).
    \item Dữ liệu: Không giống như mô hình \texttt{baseline\_linear} sử dụng bộ dữ liệu được chọn từ phương pháp chọn lọc thuộc tính ở phần trước, mô hình Ridge được huấn luyện trên bộ dữ liệu đầy đủ (đã được lưu lại vào \texttt{X\_train} và \texttt{y\_train}).
\end{itemize}
Siêu tham số \texttt{alpha} lúc này sẽ được lựa chọn thông qua các bước sau:
\begin{itemize}
    \item Định nghĩa không gian tìm kiếm: Một tập hợp các giá trị \texttt{alpha} tiềm năng được định nghĩa bằng \texttt{numpy.logspace(-4, 3, 20)}, tức là một mảng chứa 20 giá trị thực phân bố theo thang logarit từ $10^{-4}$ đến $10^3$. Việc sử dụng thang logarit cho phép khám phá hiệu qua  các giá trị ở nhiều bậc độ lớn khác nhau.
    \item Đóng gói Pipeline: Dùng chính mô hình Ridge để chuẩn hoá dữ liệu trước khi huấn luyện mô hình, mục tiêu là tìm ra và đánh giá $R^2$.
    \item Kiểm định chéo (\textit{Cross-Validation}): \texttt{GridSearchCV} được cấu hình để sử dụng phương pháp kiểm định chéo. Toàn bộ tập dữ liệu huấn luyện sẽ được chia thành 5 phần (\textit{folds}). Quá trình tìm kiếm sẽ lặp lại 5 lần, mỗi lần sẽ có một phàn được giữ lại làm tập validation tạm thời và 4 phần còn lại sẽ dùng để huấn luyện.
    \item Tiêu chí đánh giá: Chỉ số được sử dụng để đánh giá là $R^2$
    \item Lựa chọn tối ưu: quy trình \texttt{GridSearchCV} tự động huấn luyện và đánh giá mô hình Ridge với từng giá trị \texttt{alpha} trong không gian tìm kiếm. Giá trị nào mang $R^2$ trung bình cao nhất (qua 5 lượt) sẽ được chọn làm siêu tham số.
\end{itemize}
Từ quy trình trên, mô hình Ridge chọn được giá trị $\texttt{alpha}=33.6$.
\subsection{Mô hình Lasso}
\subsubsection{Cơ sở lý thuyết}

Lasso (Least Absolute Shrinkage and Selection Operator) là một phương pháp hồi quy tuyến tính sử dụng chuẩn hóa L1 (L1 regularization). Kỹ thuật này đồng thời thực hiện lựa chọn biến (variable selection) và điều chuẩn hóa (regularization) để nâng cao độ chính xác dự báo và khả năng diễn giải của mô hình. Nói cách khác, Lasso bổ sung một khoản phạt L1 vào hàm mất mát của hồi quy thường, khiến một số hệ số hồi quy bị kéo về 0, từ đó đơn giản hóa mô hình và giúp tránh hiện tượng quá khớp. \cite{tibshirani1996lasso}

Hàm mục tiêu của hồi quy Lasso (với dữ liệu có $N$ mẫu, $p$ đặc trưng) có dạng:

\[
\min_{\beta_0,\boldsymbol{\beta}}
\; \sum_{i=1}^{N} \left( y_i - \beta_0 - \sum_{j=1}^{p} x_{ij}\beta_j \right)^2
\;+\; \lambda \sum_{j=1}^{p} \lvert \beta_j \rvert
\]


trong đó vế thứ nhất là lỗi bình phương trung bình (MSE) và vế thứ hai là khoản phạt $L1$ nhân với hệ số điều chuẩn $\lambda$. Tham số $\lambda$ (ký hiệu điều chuẩn, trong scikit-learn tham số này được gọi là \texttt{alpha}) kiểm soát độ mạnh của hình phạt $L1$, qua đó quyết định mức độ phức tạp của mô hình. $\lambda$ càng lớn thì mô hình bị phạt càng nhiều: các hệ số $\beta_j$ bị kéo về 0 đáng kể hơn, nhiều hệ số nhỏ gần như bị triệt tiêu; kết quả là mô hình giữ lại rất ít biến quan trọng (tránh overfitting). Ngược lại, $\lambda$ nhỏ chỉ phạt nhẹ, mô hình sẽ giữ lại nhiều đặc trưng hơn (gần với hồi quy thường). Tài liệu từ IBM mô tả: \textit{“Larger values of lambda increase the penalty, shrinking more of the coefficients towards zero; this subsequently reduces the importance of (or altogether eliminates) some of the features from the model, resulting in automatic feature selection. Conversely, smaller values of lambda reduce the effect of the penalty, retaining more features within the model.”}\cite{ibm-lasso} (Dịch: Giá trị $\lambda$ lớn làm tăng mức phạt, kéo nhiều hệ số hơn về gần 0; điều này làm giảm tầm quan trọng (hoặc thậm chí loại bỏ hoàn toàn) một số đặc trưng khỏi mô hình, dẫn đến việc tự động chọn lọc biến. Ngược lại, giá trị $\lambda$ nhỏ làm giảm ảnh hưởng của mức phạt, giữ lại nhiều đặc trưng hơn trong mô hình). Nhìn trên phương diện bias–variance, $\lambda$ đóng vai trò cân bằng giữa độ chệch và phương sai của mô hình. Cũng theo IBM: \textit{“As $\lambda$ increases, the bias increases, and the variance decreases, leading to a simpler model with fewer parameters. Conversely, as $\lambda$ decreases, the variance increases, leading to a more complex model with more parameters. If $\lambda$ is zero, then one is left with an OLS function – that is, a standard linear regression model without any regularization.”}\cite{ibm-lasso} (Dịch: Khi $\lambda$ tăng, bias tăng và variance giảm, mô hình đơn giản hơn với ít tham số hơn. Ngược lại, khi $\lambda$ giảm, variance tăng lên, mô hình phức tạp hơn với nhiều tham số hơn. Nếu $\lambda = 0$ thì hàm mục tiêu trở thành OLS – tức là mô hình hồi quy tuyến tính thông thường không có regularization). Trường hợp $\lambda = 0$ nghĩa là không áp dụng phạt, Lasso lúc này tương đương mô hình hồi quy thường và sẽ không có tác dụng chống overfitting; ngược lại, $\lambda$ quá lớn sẽ phạt mạnh đến mức hầu hết các hệ số bị triệt tiêu về 0, mô hình khi đó có thể bị underfitting (thiếu độ linh hoạt). Do đó, việc lựa chọn $\lambda$ tối ưu là rất quan trọng để mô hình đạt hiệu năng cao nhất.

Một ưu điểm nổi bật của Lasso là khả năng chọn lọc đặc trưng tự động nhờ vào chuẩn hóa $L1$. Khoản phạt $L1$ thúc đẩy nghiệm {\it thưa} (sparse solution), nhiều hệ số hồi quy có thể bị đẩy về đúng bằng 0. Điều này có nghĩa là mô hình Lasso sẽ loại bỏ hẳn những biến không quan trọng, chỉ giữ lại những biến thật sự có đóng góp lớn. Nói cách khác, Lasso vừa giảm overfitting vừa đơn giản hóa mô hình bằng cách bỏ qua các đặc trưng dư thừa. Như IBM mô tả: \textit{“Some variables will shrink exactly to zero, leaving the model with a subset of the most important variables to make predictions.”}\cite{ibm-lasso} (Dịch: Một số biến sẽ được kéo về đúng 0, khiến mô hình chỉ còn một tập hợp các biến quan trọng nhất để dự đoán). Nhờ đó, Lasso đặc biệt hữu ích khi xử lý dữ liệu có số lượng đặc trưng rất lớn hoặc có nhiều biến ít liên quan – mô hình sẽ tự động bỏ qua những biến ít liên quan, giảm nguy cơ overfitting và cải thiện tính diễn giải (model interpretability) do mô hình trở nên gọn nhẹ hơn.

\subsubsection{Triển khai thực nghiệm}
Trong thực nghiệm, chúng tôi xây dựng một pipeline gồm hai bước: (1) Chuẩn hóa dữ liệu bằng \texttt{StandardScaler} và (2) Hồi quy Lasso (scikit-learn). Việc chuẩn hóa thang đo các đặc trưng là cần thiết trước khi áp dụng Lasso, nhằm đảm bảo các hệ số bị phạt công bằng giữa các đặc trưng. Một blog khoa học dữ liệu nhấn mạnh: \textit{“It is crucial to scale (e.g. StandardScaler) input features because regression models are sensitive to them.”}\cite{mota-lasso} (Dịch: Việc chuẩn hóa các đặc trưng đầu vào (ví dụ dùng StandardScaler) là cực kỳ quan trọng vì các mô hình hồi quy rất nhạy cảm với đặc trưng có đơn vị hay độ lớn khác nhau). Nếu không chuẩn hóa, đặc trưng có độ lớn lớn sẽ bị phạt nặng hơn đặc trưng nhỏ, dẫn đến mức phạt $L1$ không đồng đều và ảnh hưởng xấu đến kết quả hồi quy Lasso. Do đó, toàn bộ features được chuẩn hóa về trung bình 0 và phương sai 1 trước khi huấn luyện mô hình.

Tiếp theo, để tìm giá trị điều chuẩn tối ưu cho mô hình Lasso, chúng tôi sử dụng phương pháp tìm kiếm lưới kết hợp cross-validation. Cụ thể, chúng tôi thực hiện \texttt{GridSearchCV} (5-fold cross-validation, scoring theo $R^2$) trên tham số $\alpha$ của Lasso (tương ứng với $\lambda$) trong khoảng logarithmic từ $10^{-4}$ đến $10^{3}$. Việc tìm kiếm trên không gian log-space giúp thử nhiều cấp độ regularization, từ rất nhẹ đến rất mạnh. Kết quả cho thấy $\alpha \approx 78.48$ là giá trị tối ưu cho mô hình (đạt $R^2$ cao nhất trên tập validation). Với $\alpha$ này, mô hình Lasso giữ lại được độ đơn giản cần thiết đồng thời vẫn giải thích tốt phương sai của dữ liệu. Mô hình cuối cùng được huấn luyện với \texttt{alpha=78.48}, \texttt{random\_state=42} (để kết quả tái lập) và \texttt{max\_iter=10000}. Việc tăng \texttt{max\_iter} lên 10000 vòng lặp nhằm đảm bảo thuật toán Lasso (coordinate descent) hội tụ, nhất là khi $\alpha$ khá lớn.

\subsection{Mô hình Elastic Net}
\subsubsection{Cơ sở lý thuyết}

Elastic Net là một mô hình hồi quy tuyến tính kết hợp đồng thời $L1$ (như trong Lasso) và $L2$ (như trong Ridge). Mục tiêu của Elastic Net là tận dụng ưu điểm của cả hai kỹ thuật regularization: khả năng chọn lọc đặc trưng (nhờ $L1$) và khả năng ổn định mô hình khi tồn tại đa cộng tuyến (nhờ $L2$). Theo \cite{Vu_2017}, hàm mất mát của Elastic Net được định nghĩa như sau:

\[
J(w) = \frac{1}{2}\|y - Xw\|_2^2 \;+\; \lambda_1 \|w\|_1 \;+\; \lambda_2 \|w\|_2^2
\]

Trong đó, $\lambda_1$ và $\lambda_2$ lần lượt là hệ số của $L1$ và $L2$:
\begin{itemize}
    \item $\lambda_1$ càng lớn thì mô hình càng giống Lasso: nhiều hệ số được kéo về 0, thực hiện chọn lọc đặc trưng.
    \item $\lambda_2$ càng lớn thì mô hình càng giống Ridge: làm trơn mô hình và giảm mức độ nhạy với đa cộng tuyến.
\end{itemize}

Một ưu điểm nổi bật của Elastic Net là khả năng hoạt động tốt trong bối cảnh dữ liệu có nhiều đặc trưng tương quan mạnh với nhau (multicollinearity). Trong khi Lasso có xu hướng chọn một biến bất kỳ trong nhóm các biến tương quan cao, Elastic Net có khả năng giữ lại cả nhóm biến, giúp mô hình ổn định hơn. Vì vậy Elastic Net phù hợp với các bộ dữ liệu có số chiều lớn hoặc có nhiều đặc trưng không quan trọng nhưng lại liên quan lẫn nhau.

Trong scikit-learn, mô hình Elastic Net sử dụng hai tham số:
\begin{itemize}
    \item \texttt{alpha}: tổng mức phạt (\(\alpha = \lambda_1 + \lambda_2\))
    \item \texttt{l1\_ratio}: tỉ lệ giữa hai thành phần (\texttt{l1\_ratio} = $\lambda_1 / (\lambda_1 + \lambda_2)$)
\end{itemize}

Nhờ cấu trúc linh hoạt này, Elastic Net cho phép điều chỉnh mô hình đi từ Ridge ($\texttt{l1\_ratio}=0$) đến Lasso ($\texttt{l1\_ratio}=1$).

\subsubsection{Triển khai thực nghiệm}

Tương tự như các mô hình Ridge và Lasso, Elastic Net được triển khai thông qua \texttt{sklearn.pipeline.Pipeline}, trong đó bao gồm:
\begin{itemize}
    \item \textbf{Chuẩn hóa dữ liệu}: sử dụng \texttt{StandardScaler} để đảm bảo các đặc trưng có cùng thang đo, giúp regularization hoạt động đúng.
    \item \textbf{Huấn luyện mô hình ElasticNet}: sử dụng lớp \texttt{ElasticNet} của scikit-learn.
\end{itemize}

Để tìm được bộ tham số tối ưu, nhóm sử dụng \texttt{GridSearchCV} như sau:
\begin{itemize}
    \item \texttt{alpha}: quét trong khoảng \texttt{numpy.logspace(-4, 3, 20)} nhằm thử nhiều mức độ regularization từ rất nhỏ đến rất lớn.
    \item \texttt{l1\_ratio}: quét trên dãy \([0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\), cho phép mô hình dao động từ thiên về Ridge đến thiên về Lasso.
\end{itemize}

Tiêu chí đánh giá là chỉ số $R^2$, \texttt{GridSearchCV} sẽ tự động huấn luyện và đánh giá mô hình với mọi cặp giá trị (\texttt{alpha}, \texttt{l1\_ratio}), chọn ra bộ tham số mang lại hiệu suất cao nhất.

Mô hình cuối cùng được huấn luyện lại với các tham số tối ưu này trên toàn bộ tập \texttt{X\_train} và \texttt{y\_train}.