\pagebreak
\section{Lý thuyết về các mô hình và lựa chọn}
\subsection{Mô hình Linear Regression ~\cite{MachineLarning}}
Linear regression là một mô hình học có giám sát với khả năng tìm mối liên hệ tuyến tính giữa input và output.\\
\textbf{Vấn đề:} Model này nhận vào một vector $x \in \mathbb{R}^{D+1}$ gồm các đặt trưng của một mẫu và trả về giá trị dự đoán $y \in \mathbb{R}$. Ví dụ: Nhận vào các giá trị thuộc tính của một ngôi nhà như Diện tích sàn ($m^2$), số lượng phòng ngủ, khoảng cách tới trung tâm thành phố (m), tuổi nhà (năm) và trả về dự đoán giá của căn nhà đó.\\
\textbf{Đánh giá hiệu năng: }Mô hình Linear Regression thường được đánh giá bằng Mean Square Error (MSE) trên tập train:\\
\[
MSE_{\text{train}} = \frac{1}{N} \| \hat{\mathbf{y}} - \mathbf{y} \|^2 = \frac{1}{N} \sum_{n=1}^{N} (\hat{y}_n - y_n)^2
\]
với $\hat{\mathbf{y}}$ là tập giá trị dự đoán, $\mathbf{y}$ là tập giá trị thực tế của tập train.\\
\textbf{Huấn luyện mô hình}: Các phương pháp huấn luyện mô hình Linear Regression được dựa trên cách tính toán vector trọng số $\omega$ để giảm MSE xuống thấp nhất. Một cách làm phổ biến là tính toán đạo hàm của hàm MSE theo $\omega$ và cho nó bằng 0 để tìm cực tiểu.
\[
\nabla_{\mathbf{w}} (MSE_{\text{train}}) = \nabla_{\mathbf{w}} (\mathbf{w}^T \mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{w}^T \mathbf{X}^T \mathbf{y} - \mathbf{y}^T \mathbf{X} \mathbf{w} + \mathbf{y}^T \mathbf{y}) = 2\mathbf{X}^T \mathbf{X} \mathbf{w} - 2\mathbf{X}^T \mathbf{y}
\]

\begin{align*}
\nabla_{\mathbf{w}} (MSE_{\text{train}}) &= 0 \\
\mathbf{X}^T \mathbf{X} \mathbf{w} - \mathbf{X}^T \mathbf{y} &= 0 \\
\mathbf{X}^T \mathbf{X} \mathbf{w} &= \mathbf{X}^T \mathbf{y} \\
\mathbf{w} &= (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}
\end{align*}
\subsection{Mô hình Ridge}
\subsubsection{Cơ sở lý thuyết}
Hồi quy Ridge (\textbf{\textit{Ridge Regression}}) là một kỹ thuật hồi quy tuyến tính đuọc điều chỉnh (\textit{regularized}) nhằm giải quyết hiện tượng quá khớp (\textit{overfitting}) bằng cách dùng các kỹ thuật Chính quy hoá (\textit{Regularization}). Phương pháp này thêm một số hạng (thường là \textit{penalty}) vào hàm mất mát (\textit{loss function}) của mô hình. Thành phần phạt này dùng để đánh giá và kiểm soát độ phức tạp của mô hình\\
Cụ thể, mô hình Ridge sử dụng kỹ thuật \textit{L2 Regularization}, thay vì chỉ tối thiểu hoá tổng bình phương sai số (\textit{Mean Square Error - MSE}) như mô hình hồi quy tuyến tính cơ bản thì Ridge sẽ tối thiểu hoá một hàm mục tiêu mới:
\begin{center}
    $\displaystyle J(w)=\frac{1}{2}\|\mathbf{y}-\mathbf{X}\mathbf{w}\|_2^2+\lambda.\|\mathbf{w}\|_2^2$ \cite{Vu_2017}
\end{center}
Trong đó, $\mathbf{w}$ là vector trọng số của mô hình và $\lambda$ là siêu tham số (\textit{hyperparameter}) điều chỉnh độ mạnh của thành phần phạt $\|\mathbf{w}\|_2^2$.\\
\cite{Ridge} Việc thêm thành phần phạt sẽ ép các trọng số của mô hình phải giữ ở mức nhỏ, co về gần 0. Điều này làm giảm sự phụ thuộc của mô hình vào bất kỳ một biến đầu vào cụ thể nào, khiến mô hình đơn giản hơn, ít nhạy cảm với nhiễu dữ liệu và tăng khả năng tổng quát hoá. Vì thế, bài toán tối ưu hàm mất mát của hồi quy Ridge thực chất là tối ưu song song hai thành phần bao gồm tổng bình phương sai số và thành phần phạt hay thành phần điều chuẩn (\textit{regularization term}).
\begin{itemize}
    \item Trường hợp $\lambda=0$, thành phần điều chuẩn bị tiêu giảm và chúng ta quay về hồi quy tuyến tính.
    \item Trường hợp $\lambda \approx 0$, thành phần điều chuẩn trở nên ít quan trọng, mức độ kiểm soát quá khớp trở nên kém.
    \item Trường hợp $\lambda$ lớn, mức độ kiểm soát lên độ lớn của các hệ số ước lượng tăng lên qua đó giảm bớt quá khớp.
\end{itemize}
Khi $\lambda$ tăng dần, hồi quy Ridge có xu hướng thu hẹp hệ số ước lượng $\mathbf{w}$ từ mô hình.
\subsubsection{Triển khai thực nghiệm}
Mô hình Ridge được triển khai và cấu hình như sau:
\begin{itemize}
    \item Pipeline: Mô hình được gói trong một \texttt{sklearn.pipeline.Pipeline} để chuẩn hoá quy trình xử lý.
    \item Chuẩn hoá (Scaling): Bước đầu tiên trong pipeline là chuẩn hoá dữ liệu, rất quan trọng đối với các mô hình được chính quy hoá như Ridge, vì thành phần phạt nhạy cảm với sự chênh lệch về thang đo (\textit{scale}) của các biến đầu vào.
    \item Cấu hình: Mô hình Ridge được khởi tạo với siêu tham số \texttt{alpha=33.6} và \texttt{random\_state=42} (được dùng để đảm bảo kết quả có thể được tái lập).
    \item Dữ liệu: Không giống như mô hình \texttt{baseline\_linear} sử dụng bộ dữ liệu được chọn từ phương pháp chọn lọc thuộc tính ở phần trước, mô hình Ridge được huấn luyện trên bộ dữ liệu đầy đủ (đã được lưu lại vào \texttt{X\_train} và \texttt{y\_train}).
\end{itemize}
Siêu tham số \texttt{alpha} lúc này sẽ được lựa chọn thông qua các bước sau:
\begin{itemize}
    \item Định nghĩa không gian tìm kiếm: Một tập hợp các giá trị \texttt{alpha} tiềm năng được định nghĩa bằng \texttt{numpy.logspace(-4, 3, 20)}, tức là một mảng chứa 20 giá trị thực phân bố theo thang logarit từ $10^{-4}$ đến $10^3$. Việc sử dụng thang logarit cho phép khám phá hiệu qua  các giá trị ở nhiều bậc độ lớn khác nhau.
    \item Đóng gói Pipeline: Dùng chính mô hình Ridge để chuẩn hoá dữ liệu trước khi huấn luyện mô hình, mục tiêu là tìm ra và đánh giá $R^2$.
    \item Kiểm định chéo (\textit{Cross-Validation}): \texttt{GridSearchCV} được cấu hình để sử dụng phương pháp kiểm định chéo. Toàn bộ tập dữ liệu huấn luyện sẽ được chia thành 5 phần (\textit{folds}). Quá trình tìm kiếm sẽ lặp lại 5 lần, mỗi lần sẽ có một phàn được giữ lại làm tập validation tạm thời và 4 phần còn lại sẽ dùng để huấn luyện.
    \item Tiêu chí đánh giá: Chỉ số được sử dụng để đánh giá là $R^2$
    \item Lựa chọn tối ưu: quy trình \texttt{GridSearchCV} tự động huấn luyện và đánh giá mô hình Ridge với từng giá trị \texttt{alpha} trong không gian tìm kiếm. Giá trị nào mang $R^2$ trung bình cao nhất (qua 5 lượt) sẽ được chọn làm siêu tham số.
\end{itemize}
Từ quy trình trên, mô hình Ridge chọn được giá trị $\texttt{alpha}=33.6$.
\subsection{Mô hình Lasso}
\subsubsection{Cơ sở lý thuyết}

Lasso (Least Absolute Shrinkage and Selection Operator) là một phương pháp hồi quy tuyến tính sử dụng chuẩn hóa L1 (L1 regularization). Kỹ thuật này đồng thời thực hiện lựa chọn biến (variable selection) và điều chuẩn hóa (regularization) để nâng cao độ chính xác dự báo và khả năng diễn giải của mô hình. Nói cách khác, Lasso bổ sung một khoản phạt L1 vào hàm mất mát của hồi quy thường, khiến một số hệ số hồi quy bị kéo về 0, từ đó đơn giản hóa mô hình và giúp tránh hiện tượng quá khớp. \cite{tibshirani1996lasso}

Hàm mục tiêu của hồi quy Lasso (với dữ liệu có $N$ mẫu, $p$ đặc trưng) có dạng:

\[
\min_{\beta_0,\boldsymbol{\beta}}
\; \sum_{i=1}^{N} \left( y_i - \beta_0 - \sum_{j=1}^{p} x_{ij}\beta_j \right)^2
\;+\; \lambda \sum_{j=1}^{p} \lvert \beta_j \rvert
\]


trong đó vế thứ nhất là lỗi bình phương trung bình (MSE) và vế thứ hai là khoản phạt $L1$ nhân với hệ số điều chuẩn $\lambda$. Tham số $\lambda$ (ký hiệu điều chuẩn, trong scikit-learn tham số này được gọi là \texttt{alpha}) kiểm soát độ mạnh của hình phạt $L1$, qua đó quyết định mức độ phức tạp của mô hình. $\lambda$ càng lớn thì mô hình bị phạt càng nhiều: các hệ số $\beta_j$ bị kéo về 0 đáng kể hơn, nhiều hệ số nhỏ gần như bị triệt tiêu; kết quả là mô hình giữ lại rất ít biến quan trọng (tránh overfitting). Ngược lại, $\lambda$ nhỏ chỉ phạt nhẹ, mô hình sẽ giữ lại nhiều đặc trưng hơn (gần với hồi quy thường). Tài liệu từ IBM mô tả: \textit{“Larger values of lambda increase the penalty, shrinking more of the coefficients towards zero; this subsequently reduces the importance of (or altogether eliminates) some of the features from the model, resulting in automatic feature selection. Conversely, smaller values of lambda reduce the effect of the penalty, retaining more features within the model.”}\cite{ibm-lasso} (Dịch: Giá trị $\lambda$ lớn làm tăng mức phạt, kéo nhiều hệ số hơn về gần 0; điều này làm giảm tầm quan trọng (hoặc thậm chí loại bỏ hoàn toàn) một số đặc trưng khỏi mô hình, dẫn đến việc tự động chọn lọc biến. Ngược lại, giá trị $\lambda$ nhỏ làm giảm ảnh hưởng của mức phạt, giữ lại nhiều đặc trưng hơn trong mô hình). Nhìn trên phương diện bias–variance, $\lambda$ đóng vai trò cân bằng giữa độ chệch và phương sai của mô hình. Cũng theo IBM: \textit{“As $\lambda$ increases, the bias increases, and the variance decreases, leading to a simpler model with fewer parameters. Conversely, as $\lambda$ decreases, the variance increases, leading to a more complex model with more parameters. If $\lambda$ is zero, then one is left with an OLS function – that is, a standard linear regression model without any regularization.”}\cite{ibm-lasso} (Dịch: Khi $\lambda$ tăng, bias tăng và variance giảm, mô hình đơn giản hơn với ít tham số hơn. Ngược lại, khi $\lambda$ giảm, variance tăng lên, mô hình phức tạp hơn với nhiều tham số hơn. Nếu $\lambda = 0$ thì hàm mục tiêu trở thành OLS – tức là mô hình hồi quy tuyến tính thông thường không có regularization). Trường hợp $\lambda = 0$ nghĩa là không áp dụng phạt, Lasso lúc này tương đương mô hình hồi quy thường và sẽ không có tác dụng chống overfitting; ngược lại, $\lambda$ quá lớn sẽ phạt mạnh đến mức hầu hết các hệ số bị triệt tiêu về 0, mô hình khi đó có thể bị underfitting (thiếu độ linh hoạt). Do đó, việc lựa chọn $\lambda$ tối ưu là rất quan trọng để mô hình đạt hiệu năng cao nhất.

Một ưu điểm nổi bật của Lasso là khả năng chọn lọc đặc trưng tự động nhờ vào chuẩn hóa $L1$. Khoản phạt $L1$ thúc đẩy nghiệm {\it thưa} (sparse solution), nhiều hệ số hồi quy có thể bị đẩy về đúng bằng 0. Điều này có nghĩa là mô hình Lasso sẽ loại bỏ hẳn những biến không quan trọng, chỉ giữ lại những biến thật sự có đóng góp lớn. Nói cách khác, Lasso vừa giảm overfitting vừa đơn giản hóa mô hình bằng cách bỏ qua các đặc trưng dư thừa. Như IBM mô tả: \textit{“Some variables will shrink exactly to zero, leaving the model with a subset of the most important variables to make predictions.”}\cite{ibm-lasso} (Dịch: Một số biến sẽ được kéo về đúng 0, khiến mô hình chỉ còn một tập hợp các biến quan trọng nhất để dự đoán). Nhờ đó, Lasso đặc biệt hữu ích khi xử lý dữ liệu có số lượng đặc trưng rất lớn hoặc có nhiều biến ít liên quan – mô hình sẽ tự động bỏ qua những biến ít liên quan, giảm nguy cơ overfitting và cải thiện tính diễn giải (model interpretability) do mô hình trở nên gọn nhẹ hơn.

\subsubsection{Triển khai thực nghiệm}
Trong thực nghiệm, chúng tôi xây dựng một pipeline gồm hai bước: (1) Chuẩn hóa dữ liệu bằng \texttt{StandardScaler} và (2) Hồi quy Lasso (scikit-learn). Việc chuẩn hóa thang đo các đặc trưng là cần thiết trước khi áp dụng Lasso, nhằm đảm bảo các hệ số bị phạt công bằng giữa các đặc trưng. Một blog khoa học dữ liệu nhấn mạnh: \textit{“It is crucial to scale (e.g. StandardScaler) input features because regression models are sensitive to them.”}\cite{mota-lasso} (Dịch: Việc chuẩn hóa các đặc trưng đầu vào (ví dụ dùng StandardScaler) là cực kỳ quan trọng vì các mô hình hồi quy rất nhạy cảm với đặc trưng có đơn vị hay độ lớn khác nhau). Nếu không chuẩn hóa, đặc trưng có độ lớn lớn sẽ bị phạt nặng hơn đặc trưng nhỏ, dẫn đến mức phạt $L1$ không đồng đều và ảnh hưởng xấu đến kết quả hồi quy Lasso. Do đó, toàn bộ features được chuẩn hóa về trung bình 0 và phương sai 1 trước khi huấn luyện mô hình.

Tiếp theo, để tìm giá trị điều chuẩn tối ưu cho mô hình Lasso, chúng tôi sử dụng phương pháp tìm kiếm lưới kết hợp cross-validation. Cụ thể, chúng tôi thực hiện \texttt{GridSearchCV} (5-fold cross-validation, scoring theo $R^2$) trên tham số $\alpha$ của Lasso (tương ứng với $\lambda$) trong khoảng logarithmic từ $10^{-4}$ đến $10^{3}$. Việc tìm kiếm trên không gian log-space giúp thử nhiều cấp độ regularization, từ rất nhẹ đến rất mạnh. Kết quả cho thấy $\alpha \approx 78.48$ là giá trị tối ưu cho mô hình (đạt $R^2$ cao nhất trên tập validation). Với $\alpha$ này, mô hình Lasso giữ lại được độ đơn giản cần thiết đồng thời vẫn giải thích tốt phương sai của dữ liệu. Mô hình cuối cùng được huấn luyện với \texttt{alpha=78.48}, \texttt{random\_state=42} (để kết quả tái lập) và \texttt{max\_iter=10000}. Việc tăng \texttt{max\_iter} lên 10000 vòng lặp nhằm đảm bảo thuật toán Lasso (coordinate descent) hội tụ, nhất là khi $\alpha$ khá lớn.

\subsection{Mô hình Elastic Net}

Theo \cite{Vu_2017}, khi kết hợp cả hai dạng regularization $l_1$ và $l_2$, ta thu được mô hình Elastic Net Regression.
Lúc đó, \textbf{hàm loss của Elastic Net} sẽ có dạng:
\[
J(w) = \frac{1}{2} \|y - Xw\|_2^2 + \lambda_1 \|w\|_1 + \lambda_2 \|w\|_2^2
\]
trong đó, $\lambda_1$ và $\lambda_2$ lần lượt là các hệ số điều chuẩn tương ứng với $l_1$ và $l_2$ regularization, giúp cân bằng giữa khả năng chọn lọc đặc trưng và việc giảm độ phức tạp của mô hình.
Nhờ đó, Elastic Net đặc biệt hữu ích khi dữ liệu vừa chứa nhiều đặc trưng không quan trọng, vừa tồn tại hiện tượng đa cộng tuyến (multicollinearity) giữa các biến.

